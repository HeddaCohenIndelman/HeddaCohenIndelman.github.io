<!doctype html>
<!--[if lt IE 7]>      <html class="no-js lt-ie9 lt-ie8 lt-ie7" lang=""> <![endif]-->
<!--[if IE 7]>         <html class="no-js lt-ie9 lt-ie8" lang=""> <![endif]-->
<!--[if IE 8]>         <html class="no-js lt-ie9" lang=""> <![endif]-->
<!--[if gt IE 8]><!-->
<html class="no-js" lang="">
<!--<![endif]-->
<head>
  <script type='text/javascript'>
    window.smartlook||(function(d) {
      var o=smartlook=function(){ o.api.push(arguments)},h=d.getElementsByTagName('head')[0];
      var c=d.createElement('script');o.api=new Array();c.async=true;c.type='text/javascript';
      c.charset='utf-8';c.src='https://web-sdk.smartlook.com/recorder.js';h.appendChild(c);
      })(document);
      smartlook('init', '2836317c66a3363e799570f4a4f128b7de13c51c', { region: 'eu' });
  </script>
<meta charset="utf-8">
<meta name="description" content="">
<meta name="viewport" content="width=device-width, initial-scale=1">
<title>Itai Gat</title>
<link rel="stylesheet" href="css/bootstrap.min.css">
<link rel="stylesheet" href="css/flexslider.css">
<link rel="stylesheet" href="css/jquery.fancybox.css">
<link rel="stylesheet" href="css/main.css">
<link rel="stylesheet" href="css/responsive.css">
<link rel="stylesheet" href="css/animate.min.css">
<link rel="stylesheet" href="css/font-icon.css">
<link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/font-awesome/4.4.0/css/font-awesome.min.css">
<link href="css/academicons/css/academicons.min.css" rel="stylesheet">
</head>
<body>

<!-- header top section -->
<!-- <section class="banner" role="banner">
  <header id="header">
    <div class="header-content clearfix">
      <nav class="navigation" role="navigation">
        <ul class="primary-nav">
          <li><a href="#home">Home</a></li>
          <li><a href="#publications">Publications</a></li>
        </ul>
      </nav>
      <a href="#" class="nav-toggle">Menu<span></span></a> </div>
  </header>
</section> -->
<!-- header top section --> 
<!-- header content section -->
<section id="hero" class="section ">
  <div class="container">
    <div class="row">
      <!-- <div class="col-md-7 col-sm-6 hero"> -->
      <!-- <div class="col-md-5 col-sm-6 hero"> -->
      <div class="col-md-5 col-sm-6 hero">
        <div class="hero-content">
          <img class="img-fluid img-profile rounded-circle mx-auto mb-2" width="200" src="images/prof_pic.jpeg" alt="">
          <h2><b>Itai</b> Gat</h2>
        </div>
        <!-- hero --> 
      </div>
      <div class="col-md-7 col-sm-6 hero">
        <div class="hero-content">
          <p>
            I am a Ph.D. student under the supervision of Professor Tamir Hazan at the Technion - Israel Institute of Technology. I graduated with my BSc degree in Data Science and Engineering from the Technion. My research is focused on the perception of deep learning classifiers, primarily with applications to multi-modal tasks. On a variety of well-known benchmarks, we discover surprising insights and achieve state-of-the-art results.
          </p>
          <br><br>
          <i class="fa fa-envelope"></i> itaigat dot mail at gmail dot com</a>
          <br><br>
          <a href="https://github.com/itaigat" target="_blank" class="social">
            <span class="fa-stack fa-lg">
              <i class="fa fa-circle fa-stack-2x"></i>
              <i class="fa fa-github fa-stack-1x fa-inverse"></i>
            </span>
          </a>
          <a href="https://scholar.google.com/citations?user=TnJqhXIAAAAJ" target="_blank" class="social">
            <span class="fa-stack fa-lg">
              <i class="fa fa-circle fa-stack-2x"></i>
              <i class="ai ai-google-scholar fa-stack-2x fa-inverse"></i>
            </span>
          </a>
          <a href="https://www.linkedin.com/in/itaigat/" target="_blank" class="social">
            <span class="fa-stack fa-lg">
              <i class="fa fa-circle fa-stack-2x"></i>
              <i class="fa fa-linkedin fa-stack-1x fa-inverse"></i>
            </span>
          </a>
          <a href="https://twitter.com/Itai_Gat" target="_blank" class="social">
            <span class="fa-stack fa-lg">
              <i class="fa fa-circle fa-stack-2x"></i>
              <i class="fa fa-twitter fa-stack-1x fa-inverse"></i>
            </span>
          </a>
        </div>
      </div>
    </div>
  </div>
</section>
<section id="publications" class="service section">
	<div class="container">
		<div class="row">
			<div class="col-md-12 text-left">
				<div class="my-auto">
          <h2 class="mb-5">Publications</h2>
          <div class="resume-item d-flex flex-column flex-md-row mb-5">
            <div class="resume-content mr-auto">
              <ol>
                
                
                  
                    <h3>2023</h3>
                    
                  
                  <li id="paper"  class="mb-1"> <b>Simple and Controllable Music Generation</b>. Jade Copet, Felix Kreuk, <u>Itai Gat</u>, Tal Remez, David Kant, Gabriel Synnaeve, Yossi Adi, Alexandre Défossez. <em>arXiv, 2023</em> </li>
                  [
                    <a href="https://arxiv.org/abs/2306.05284" target="_blank">PDF,</a>
                  
                    <a href="https://huggingface.co/spaces/facebook/MusicGen" target="_blank">Demo,</a>
                  
                    <a href="https://github.com/facebookresearch/audiocraft" target="_blank">Code,</a>
                  
                  
                    <a class="bibtex-link" href="#">BibTeX</a>
                  
                  ]
                  
                  <div class="bibtex-content" style="display: none; padding: 10px; background-color: #f0f0f0; border: 1px solid #ccc; border-radius: 4px;">
                  <br>
                  <pre style="line-height: 1.5; font-family: 'Courier New', monospace;">
                    <pre>
                    
        @misc{copet2023simple,
            title={Simple and Controllable Music Generation}, 
            author={Jade Copet and Felix Kreuk and Itai Gat and Tal Remez and David Kant and Gabriel Synnaeve and Yossi Adi and Alexandre Défossez},
            year={2023},
            eprint={2306.05284},
            archivePrefix={arXiv},
            primaryClass={cs.SD}
        }
        
                    </pre>
                  </div>
                  
                
                  
                  <li id="paper"  class="mb-1"> <b>Textually Pretrained Speech Language Models</b>. Michael Hassid, Tal Remez, Tu Anh Nguyen, <u>Itai Gat</u>, Alexis Conneau, Felix Kreuk, Jade Copet, Alexandre Defossez, Gabriel Synnaeve, Emmanuel Dupoux, Roy Schwartz, Yossi Adi. <em>arXiv, 2023</em> </li>
                  [
                    <a href="https://arxiv.org/abs/2305.13009" target="_blank">PDF,</a>
                  
                    <a href="https://pages.cs.huji.ac.il/adiyoss-lab/twist/" target="_blank">Samples,</a>
                  
                  
                    <a class="bibtex-link" href="#">BibTeX</a>
                  
                  ]
                  
                  <div class="bibtex-content" style="display: none; padding: 10px; background-color: #f0f0f0; border: 1px solid #ccc; border-radius: 4px;">
                  <br>
                  <pre style="line-height: 1.5; font-family: 'Courier New', monospace;">
                    <pre>
                    
        @misc{hassid2023textually,
        title={Textually Pretrained Speech Language Models}, 
        author={Michael Hassid and Tal Remez and Tu Anh Nguyen and Itai Gat and Alexis Conneau and Felix Kreuk and Jade Copet and Alexandre Defossez and Gabriel Synnaeve and Emmanuel Dupoux and Roy Schwartz and Yossi Adi},
        year={2023},
        eprint={2305.13009},
        archivePrefix={arXiv},}
        
                    </pre>
                  </div>
                  
                
                  
                  <li id="paper"  class="mb-1"> <b>Expresso: A Benchmark and Analysis of Discrete Expressive Speech Resynthesis</b>. Tu Anh Nguyen, Wei-Ning Hsu, Antony d'Avirro, Bowen Shi, <u>Itai Gat</u>, Maryam Fazel-Zarandi, Tal Remez, Jade Copet, Gabriel Synnaeve, Michael Hassid, Felix Kreuk, Yossi Adi, Emmanuel Dupoux. <em>International Speech Communication Association (Interspeech), 2023</em> </li>
                  [
                    <a href="https://arxiv.org/abs/2308.05725" target="_blank">PDF,</a>
                  
                  
                    <a class="bibtex-link" href="#">BibTeX</a>
                  
                  ]
                  
                  <div class="bibtex-content" style="display: none; padding: 10px; background-color: #f0f0f0; border: 1px solid #ccc; border-radius: 4px;">
                  <br>
                  <pre style="line-height: 1.5; font-family: 'Courier New', monospace;">
                    <pre>
                    
        @inproceedings{expresso2023,
        title={Expresso: A Benchmark and Analysis of Discrete Expressive Speech Resynthesis}, 
        author={Tu Anh Nguyen, Wei-Ning Hsu, Antony d'Avirro, Bowen Shi, Itai Gat, Maryam Fazel-Zarandi, Tal Remez, Jade Copet, Gabriel Synnaeve, Michael Hassid, Felix Kreuk, Yossi Adi, Emmanuel Dupoux},
        booktitle={INTERSPEECH},
        year={2023}}
        
                    </pre>
                  </div>
                  
                
                  
                  <li id="paper"  class="mb-1"> <b>AudioToken: Adaptation of Text-Conditioned Diffusion Models for Audio-to-Image Generation</b>. Guy Yariv, <u>Itai Gat</u>, Lior Wolf, Yossi Adi, Idan Schwartz. <em>INTERSPEECH, 2023</em> </li>
                  [
                    <a href="https://arxiv.org/abs/2305.13050" target="_blank">PDF,</a>
                  
                    <a href="https://pages.cs.huji.ac.il/adiyoss-lab/AudioToken/" target="_blank">Page,</a>
                  
                    <a href="https://github.com/guyyariv/AudioToken" target="_blank">Code,</a>
                  
                  
                    <a class="bibtex-link" href="#">BibTeX</a>
                  
                  ]
                  
                  <div class="bibtex-content" style="display: none; padding: 10px; background-color: #f0f0f0; border: 1px solid #ccc; border-radius: 4px;">
                  <br>
                  <pre style="line-height: 1.5; font-family: 'Courier New', monospace;">
                    <pre>
                    
        @inproceedings{yarivAudiotoken,
        title={AudioToken: Adaptation of Text-Conditioned Diffusion Models for Audio-to-Image Generation},
        author={Guy Yariv, Itai Gat, Lior Wolf, Yossi Adi, Idan Schwartz},
        booktitle={INTERSPEECH},
        year={2023}}
        
                    </pre>
                  </div>
                  
                
                  
                  <li id="paper"  class="mb-1"> <b>Layer Collaboration in the Forward-Forward Algorithm</b>. Guy Lorberbom*, <u>Itai Gat</u>*, Yossi Adi, Alex Schwing, Tamir Hazan. <em>arXiv, 2023</em> </li>
                  [
                    <a href="https://arxiv.org/abs/2305.12393" target="_blank">PDF,</a>
                  
                  
                    <a class="bibtex-link" href="#">BibTeX</a>
                  
                  ]
                  
                  <div class="bibtex-content" style="display: none; padding: 10px; background-color: #f0f0f0; border: 1px solid #ccc; border-radius: 4px;">
                  <br>
                  <pre style="line-height: 1.5; font-family: 'Courier New', monospace;">
                    <pre>
                    
        @misc{lorberbom2023layer,
        title={Layer Collaboration in the Forward-Forward Algorithm}, 
        author={Guy Lorberbom and Itai Gat and Yossi Adi and Alex Schwing and Tamir Hazan},
        year={2023},
        eprint={2305.12393},
        archivePrefix={arXiv},
        primaryClass={cs.LG}}
        
                    </pre>
                  </div>
                  
                
                  
                  <li id="paper"  class="mb-1"> <b>Augmentation Invariant Discrete Representation for Generative Spoken Language Modeling (Oral)</b>. <u>Itai Gat</u>, Felix Kreuk, Tu Anh Nguyen, Ann Lee, Jade Copet, Gabriel Synnaeve, Emmanuel Dupoux, Yossi Adi. <em>International Conference on Spoken Language Translation (IWSLT), 2023</em> </li>
                  [
                    <a href="https://arxiv.org/abs/2209.15483" target="_blank">PDF,</a>
                  
                  
                    <a class="bibtex-link" href="#">BibTeX</a>
                  
                  ]
                  
                  <div class="bibtex-content" style="display: none; padding: 10px; background-color: #f0f0f0; border: 1px solid #ccc; border-radius: 4px;">
                  <br>
                  <pre style="line-height: 1.5; font-family: 'Courier New', monospace;">
                    <pre>
                    
        @inproceedings{augmentationgat23,
        title={Augmentation Invariant Discrete Representation for Generative Spoken Language Modeling},
        author={Itai Gat, Felix Kreuk, Tu Anh Nguyen, Ann Lee, Jade Copet, Gabriel Synnaeve, Emmanuel Dupoux, Yossi Adi},
        booktitle={IWSLT},
        year={2023}}
        
                    </pre>
                  </div>
                  
                
                  
                    <h3>2022</h3>
                    
                  
                  <li id="paper"  class="mb-1"> <b>On the Importance of Gradient Norm in PAC-Bayesian Bounds</b>. <u>Itai Gat</u>, Yossi Adi, Alex Schwing, Tamir Hazan. <em>Advances in Neural Information Processing Systems (NeurIPS), 2022</em> </li>
                  [
                    <a href="https://proceedings.neurips.cc/paper_files/paper/2022/file/6686e3f2e31a0db5bf90ab1cc2272b72-Paper-Conference.pdf" target="_blank">PDF,</a>
                  
                  
                    <a class="bibtex-link" href="#">BibTeX</a>
                  
                  ]
                  
                  <div class="bibtex-content" style="display: none; padding: 10px; background-color: #f0f0f0; border: 1px solid #ccc; border-radius: 4px;">
                  <br>
                  <pre style="line-height: 1.5; font-family: 'Courier New', monospace;">
                    <pre>
                    
        @inproceedings{gat2022importance,
        title={On the Importance of Gradient Norm in PAC-Bayesian Bounds},
        author={Gat, Itai and Adi, Yossi and Schwing, Alexander and Hazan, Tamir},
        booktitle={NeurIPS},
        year={2022}}
        
                    </pre>
                  </div>
                  
                
                  
                  <li id="paper"  class="mb-1"> <b>On The Robustness of Self-Supervised Representations for Spoken Language Modeling</b>. <u>Itai Gat</u>, Felix Kreuk, Ann Lee, Jade Copet, Gabriel Synnaeve, Emmanuel Dupoux, Yossi Adi. <em>arXiv, 2022</em> </li>
                  [
                    <a href="https://arxiv.org/abs/2209.15483" target="_blank">PDF,</a>
                  
                  
                    <a class="bibtex-link" href="#">BibTeX</a>
                  
                  ]
                  
                  <div class="bibtex-content" style="display: none; padding: 10px; background-color: #f0f0f0; border: 1px solid #ccc; border-radius: 4px;">
                  <br>
                  <pre style="line-height: 1.5; font-family: 'Courier New', monospace;">
                    <pre>
                    
        @inproceedings{gat2022robustness,
        title={On the robustness of self-supervised representations for spoken language modeling},
        author={Gat, Itai and Kreuk, Felix and Lee, Ann and Copet, Jade and Synnaeve, Gabriel and Dupoux, Emmanuel and Adi, Yossi},
        booktitle={arXiv},
        year={2022}}
        
                    </pre>
                  </div>
                  
                
                  
                  <li id="paper"  class="mb-1"> <b>A Functional Information Perspective on Model Interpretation</b>. <u>Itai Gat</u>, Nitay Calderon, Roi Reichart, Tamir Hazan. <em>Proceedings of the International Conference on Machine Learning (ICML), 2022</em> </li>
                  [
                    <a href="https://proceedings.mlr.press/v162/gat22a/gat22a.pdf" target="_blank">PDF,</a>
                  
                    <a href="https://github.com/nitaytech/FunctionalExplanation" target="_blank">Code,</a>
                  
                  
                    <a class="bibtex-link" href="#">BibTeX</a>
                  
                  ]
                  
                  <div class="bibtex-content" style="display: none; padding: 10px; background-color: #f0f0f0; border: 1px solid #ccc; border-radius: 4px;">
                  <br>
                  <pre style="line-height: 1.5; font-family: 'Courier New', monospace;">
                    <pre>
                    
        @inproceedings{gat22functional,
        title={A Functional Information Perspective on Model Interpretation},
        author={Gat, Itai and Calderon, Nitay and Reichart, Roi and Hazan, Tamir},
        booktitle={ICML},
        year ={2022},}
        
                    </pre>
                  </div>
                  
                
                  
                  <li id="paper"  class="mb-1"> <b>Speech Emotion Recognition using Self-Supervised Features</b>. Edmilson Morais, Ron Hoory, Weizhong Zhu, <u>Itai Gat</u>, Matheus Damasceno, Hagai Aronowitz. <em>IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), 2022</em> </li>
                  [
                    <a href="https://arxiv.org/abs/2202.03896" target="_blank">PDF,</a>
                  
                  
                    <a class="bibtex-link" href="#">BibTeX</a>
                  
                  ]
                  
                  <div class="bibtex-content" style="display: none; padding: 10px; background-color: #f0f0f0; border: 1px solid #ccc; border-radius: 4px;">
                  <br>
                  <pre style="line-height: 1.5; font-family: 'Courier New', monospace;">
                    <pre>
                    
        @inproceedings{Edmilson22SF,
        title={Speech Emotion Recognition using Self-supervised Features},
        author={Morais, Edmilson and Hoory, Ron and Zhu, Weizhong and Gat, Itai and Damasceno, Matheus and Aronowitz, Hagai},
        booktitle={ICASSP},
        year={2022}}
        
                    </pre>
                  </div>
                  
                
                  
                  <li id="paper"  class="mb-1"> <b>Speaker Normalization for Self-supervised Speech Emotion Recognition</b>. <u>Itai Gat</u>, Hagai Aronowitz, Weizhong Zhu, Edmilson Morais, Ron Hoory. <em>IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), 2022</em> </li>
                  [
                    <a href="https://arxiv.org/abs/2202.01252" target="_blank">PDF,</a>
                  
                  
                    <a class="bibtex-link" href="#">BibTeX</a>
                  
                  ]
                  
                  <div class="bibtex-content" style="display: none; padding: 10px; background-color: #f0f0f0; border: 1px solid #ccc; border-radius: 4px;">
                  <br>
                  <pre style="line-height: 1.5; font-family: 'Courier New', monospace;">
                    <pre>
                    
        @inproceedings{gat2022speaker,
        title={Speaker Normalization for Self-supervised Speech Emotion Recognition},
        author={Gat, Itai and Aronowitz, Hagai and Zhu, Weizhong and Morais, Edmilson and Hoory, Ron},
        booktitle={ICASSP},
        year={2022}}
        
                    </pre>
                  </div>
                  
                
                  
                  <li id="paper"  class="mb-1"> <b>Towards a Common Speech Analysis Engine</b>. Hagai Aronowitz, <u>Itai Gat</u>, Edmilson Morais, Weizhong Zhu, Ron Hoory. <em>IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), 2022</em> </li>
                  [
                    <a href="https://arxiv.org/abs/2203.00613" target="_blank">PDF,</a>
                  
                  
                    <a class="bibtex-link" href="#">BibTeX</a>
                  
                  ]
                  
                  <div class="bibtex-content" style="display: none; padding: 10px; background-color: #f0f0f0; border: 1px solid #ccc; border-radius: 4px;">
                  <br>
                  <pre style="line-height: 1.5; font-family: 'Courier New', monospace;">
                    <pre>
                    
        @inproceedings{Aronowitz2022towards,
        title={Towards a Common Speech Analysis Engine},
        author={Aronowitz, Hagai and Gat, Itai and Morais, Edmilson and Zhu, Weizhong and Hoory, Ron},
        booktitle={ICASSP},
        year={2022}}
        
                    </pre>
                  </div>
                  
                
                  
                    <h3>2021</h3>
                    
                  
                  <li id="paper"  class="mb-1"> <b>Latent Space Explanation by Intervention</b>. <u>Itai Gat</u>*, Guy Lorberbom*, Idan Schwartz, Tamir Hazan. <em>Proceedings of the AAAI Conference on Artificial Intelligence, 2021</em> </li>
                  [
                    <a href="https://ojs.aaai.org/index.php/AAAI/article/view/19948" target="_blank">PDF,</a>
                  
                  
                    <a class="bibtex-link" href="#">BibTeX</a>
                  
                  ]
                  
                  <div class="bibtex-content" style="display: none; padding: 10px; background-color: #f0f0f0; border: 1px solid #ccc; border-radius: 4px;">
                  <br>
                  <pre style="line-height: 1.5; font-family: 'Courier New', monospace;">
                    <pre>
                    
        @inproceedings{2022latentSpaceExplainations,
        title={Latent Space Explanation by Intervention},
        author={Gat, Itai and Lorberbom, Guy and Schwartz, Idan and Hazan, Tamir},
        booktitle={AAAI},
        year={2022}}
        
                    </pre>
                  </div>
                  
                
                  
                  <li id="paper"  class="mb-1"> <b>Perceptual Score: What Data Modalities Does Your Model Perceive?</b>. <u>Itai Gat</u>, Idan Schwartz, Alexander Schwing. <em>Advances in Neural Information Processing Systems (NeurIPS), 2021</em> </li>
                  [
                    <a href="https://proceedings.neurips.cc/paper/2021/file/b51a15f382ac914391a58850ab343b00-Paper.pdf" target="_blank">PDF,</a>
                  
                    <a href="https://github.com/itaigat/perceptual-score" target="_blank">Code,</a>
                  
                  
                    <a class="bibtex-link" href="#">BibTeX</a>
                  
                  ]
                  
                  <div class="bibtex-content" style="display: none; padding: 10px; background-color: #f0f0f0; border: 1px solid #ccc; border-radius: 4px;">
                  <br>
                  <pre style="line-height: 1.5; font-family: 'Courier New', monospace;">
                    <pre>
                    
        @inproceedings{gat2021perceptual,
        title={Perceptual Score: What Data Modalities Does Your Model Perceive?},
        author={Gat, Itai and Schwartz, Idan and Schwing, Alex},
        booktitle={NeurIPS},
        year={2021}}
        
                    </pre>
                  </div>
                  
                
                  
                  <li id="paper"  class="mb-1"> <b>Are VQA Systems RAD? Measuring Robustness to Augmented Data with Focused Interventions</b>. Daniel Rosenberg, <u>Itai Gat</u>, Amir Feder, Roi Reichart. <em>Association for Computational Linguistics (ACL), 2021</em> </li>
                  [
                    <a href="https://arxiv.org/abs/2106.04484" target="_blank">PDF,</a>
                  
                    <a href="https://danrosenberg.github.io/rad-measure/" target="_blank">Page,</a>
                  
                  
                    <a class="bibtex-link" href="#">BibTeX</a>
                  
                  ]
                  
                  <div class="bibtex-content" style="display: none; padding: 10px; background-color: #f0f0f0; border: 1px solid #ccc; border-radius: 4px;">
                  <br>
                  <pre style="line-height: 1.5; font-family: 'Courier New', monospace;">
                    <pre>
                    
            @inproceedings{acl_rosen,
            author={Daniel Rosenberg and Itai Gat and Amir Feder and Roi Reichart},
            title= {Are {VQA} Systems RAD? Measuring Robustness to Augmented Data with
                        Focused Interventions},
            booktitle = {ACL},
            year = {2021}}
        
                    </pre>
                  </div>
                  
                
                  
                    <h3>2020</h3>
                    
                  
                  <li id="paper"  class="mb-1"> <b>Removing Bias in Multi-modal Classifiers: Regularization by Maximizing Functional Entropies</b>. <u>Itai Gat</u>, Idan Schwartz, Alexander Schwing, Tamir Hazan. <em>Advances in Neural Information Processing Systems (NeurIPS), 2020</em> </li>
                  [
                    <a href="https://proceedings.neurips.cc/paper/2020/file/20d749bc05f47d2bd3026ce457dcfd8e-Paper.pdf" target="_blank">PDF,</a>
                  
                    <a href="https://github.com/itaigat/removing-bias-in-multi-modal-classifiers" target="_blank">Code,</a>
                  
                  
                    <a class="bibtex-link" href="#">BibTeX</a>
                  
                  ]
                  
                  <div class="bibtex-content" style="display: none; padding: 10px; background-color: #f0f0f0; border: 1px solid #ccc; border-radius: 4px;">
                  <br>
                  <pre style="line-height: 1.5; font-family: 'Courier New', monospace;">
                    <pre>
                    
        @inproceedings{gat2020,
        author = {Gat, Itai and Schwartz, Idan and Schwing, Alexander and Hazan, Tamir},
        booktitle = {Advances in Neural Information Processing Systems},
        title = {Removing Bias in Multi-modal Classifiers: Regularization by Maximizing Functional Entropies},
        year = {2020}}
        
                    </pre>
                  </div>
                  
                
              </ol>
            </div>
          </div>                            
        </div>
			</div>
		</div>
	</div>
</section>


<!-- JS FILES --> 
<script src="https://ajax.googleapis.com/ajax/libs/jquery/1.11.3/jquery.min.js"></script> 
<script src="js/bootstrap.min.js"></script> 
<script src="js/jquery.fancybox.pack.js"></script> 
<script src="js/retina.min.js"></script> 
<script src="js/modernizr.js"></script> 
<script src="js/main.js"></script>
</body>
</html>